<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="K5MPN7tKaH-0M_0Mq2-YLIOuK5v55-KC7Tx-w-AREw8"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Chao-Wei Huang </title> <meta name="author" content="Chao-Wei Huang"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website, NLP, speech, natural language processing, LLM"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%91%A8%F0%9F%8F%BB%E2%80%8D%F0%9F%92%BB&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://chaoweihuang.github.io/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <div class="navbar-brand social"> <a href="mailto:%63%68%61%6F%77%65%69%68%75%61%6E%67.%75%73@%67%6D%61%69%6C.%63%6F%6D" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=nmsPLncAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/chaoweihuang" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/chao-wei-huang-89933a163" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://twitter.com/cwhuang_wh" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> </div> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/assets/pdf/ChaoWei_Resume_20241017.pdf">CV </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Chao-Wei</span> Huang </h1> <p class="desc">Ph.D., <a href="https://www.ntu.edu.tw/english/" rel="external nofollow noopener" target="_blank">National Taiwan University</a>.</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof_pic.jpg" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/prof_pic.jpg?b7692173bb23a094909a497fe8aee252" class="img-fluid z-depth-1 rounded-circle" width="100%" height="auto" alt="prof_pic.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"></div> </div> <div class="clearfix"> <p>Hi! My name is Chao-Wei Huang. I received my B.S. and Ph.D. from National Taiwan University, advised by <a href="https://www.csie.ntu.edu.tw/~yvchen/" rel="external nofollow noopener" target="_blank">Prof. Yun-Nung (Vivian) Chen</a>.</p> <p>My research interests include <strong>information retrieval</strong>, <strong>factuality</strong>, <strong>large language models</strong>, and <strong>speech processing</strong>. My research has been published in top-tier speech and natural language processing conferences, e.g., ACL, EMNLP, NAACL, ICASSP, Interspeech, and EACL. Driven by a commitment to fostering academic collaboration, I have co-organized <a href="https://dstc9.dstc.community/" rel="external nofollow noopener" target="_blank">The 9th Dialog System Technology Challenge (DSTC9)</a> and the <a href="https://ctrlnlg.github.io/" rel="external nofollow noopener" target="_blank">1st TamingLLM workshop</a>. Previously, I worked as a Research Scientist Intern at <strong>Amazon Alexa AI</strong> (‚Äò20, ‚Äò21) and <strong>Meta AI Research</strong> (‚Äò22, ‚Äò23).</p> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Sep 20, 2024</th> <td> Excited to share that 4 papers (2 first-authored) have been accepted to <a href="https://2024.emnlp.org/" rel="external nofollow noopener" target="_blank">EMNLP 2024</a>! üéâ </td> </tr> <tr> <th scope="row" style="width: 20%">Sep 11, 2024</th> <td> PhDone! I have received my Ph.D. degree from <a href="https://www.ntu.edu.tw/english/" rel="external nofollow noopener" target="_blank">National Taiwan University</a>! </td> </tr> <tr> <th scope="row" style="width: 20%">Aug 28, 2024</th> <td> I‚Äôm giving an oral presentation of our paper ‚ÄúInvestigating Decoder-only Large Language Models for Speech-to-text Translation‚Äù at <a href="https://www.interspeech2024.org/" rel="external nofollow noopener" target="_blank">Interspeech 2024</a> at Kos Island, Greece. üá¨üá∑ </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">EMNLP 2024</abbr> </div> <div id="huang2024factalign" class="col-sm-8"> <div class="title">FactAlign: Long-form Factuality Alignment of Large Language Models</div> <div class="author"> <em>Chao-Wei Huang</em>,¬†and¬†<a href="https://www.csie.ntu.edu.tw/~yvchen/" rel="external nofollow noopener" target="_blank">Yun-Nung Chen</a> </div> <div class="periodical"> <em>In Findings of the Association for Computational Linguistics: EMNLP 2024</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/abs/2410.01691" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://github.com/MiuLab/FactAlign" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">huang2024factalign</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{FactAlign: Long-form Factuality Alignment of Large Language Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Huang, Chao-Wei and Chen, Yun-Nung}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Findings of the Association for Computational Linguistics: EMNLP 2024}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">paper</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2410.01691}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">EMNLP 2024</abbr> </div> <div id="huang2024pairdistill" class="col-sm-8"> <div class="title">PairDistill: Pairwise Relevance Distillation for Dense Passage Retrieval</div> <div class="author"> <em>Chao-Wei Huang</em>,¬†and¬†<a href="https://www.csie.ntu.edu.tw/~yvchen/" rel="external nofollow noopener" target="_blank">Yun-Nung Chen</a> </div> <div class="periodical"> <em>In Proceedings of The 2024 Conference on Empirical Methods in Natural Language Processing (EMNLP 2024)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/abs/2410.01383" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://github.com/MiuLab/PairDistill" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">huang2024pairdistill</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{PairDistill: Pairwise Relevance Distillation for Dense Passage Retrieval}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Huang, Chao-Wei and Chen, Yun-Nung}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of The 2024 Conference on Empirical Methods in Natural Language Processing (EMNLP 2024)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">paper</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2410.01383}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Interspeech 2024</abbr> </div> <div id="huang2024investigating" class="col-sm-8"> <div class="title">Investigating Decoder-only Large Language Models for Speech-to-text Translation</div> <div class="author"> <em>Chao-Wei Huang</em>,¬†Hui Lu,¬†Hongyu Gong, and <span class="more-authors" title="click to view 4 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '4 more authors' ? 'Hirofumi Inaguma, Ilia Kulikov, Ruslan Mavlyutov, Sravya Popuri' : '4 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">4 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/abs/2407.03169" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">huang2024investigating</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Investigating Decoder-only Large Language Models for Speech-to-text Translation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Huang, Chao-Wei and Lu, Hui and Gong, Hongyu and Inaguma, Hirofumi and Kulikov, Ilia and Mavlyutov, Ruslan and Popuri, Sravya}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">paper</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2407.03169}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">EACL 2024</abbr> </div> <div id="huang2024umr" class="col-sm-8"> <div class="title">Unsupervised Multilingual Dense Retrieval via Generative Pseudo Labeling</div> <div class="author"> <em>Chao-Wei Huang</em>,¬†Tsu-Yuan Hsu,¬†Chen-An Li, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Chen-Yu Hsu, Yun-Nung Chen' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2024)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://aclanthology.org/2024.findings-eacl.49/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://github.com/MiuLab/UMR" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">huang2024umr</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Unsupervised Multilingual Dense Retrieval via Generative Pseudo Labeling}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Huang, Chao-Wei and Hsu, Tsu-Yuan and Li, Chen-An and Hsu, Chen-Yu and Chen, Yun-Nung}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2024)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">paper</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/2024.findings-eacl.49/}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">EMNLP 2024</abbr> </div> <div id="tseng2024talespersonallmssurvey" class="col-sm-8"> <div class="title">Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization</div> <div class="author"> Yu-Min Tseng,¬†Yu-Chao Huang,¬†Teng-Yun Hsiao, and <span class="more-authors" title="click to view 4 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '4 more authors' ? 'Wei-Lin Chen, Chao-Wei Huang, Yu Meng, Yun-Nung Chen' : '4 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">4 more authors</span> </div> <div class="periodical"> <em>In Findings of the Association for Computational Linguistics: EMNLP 2024</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/abs/2406.01171" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://github.com/MiuLab/PersonaLLM-Survey" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">tseng2024talespersonallmssurvey</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Tseng, Yu-Min and Huang, Yu-Chao and Hsiao, Teng-Yun and Chen, Wei-Lin and Huang, Chao-Wei and Meng, Yu and Chen, Yun-Nung}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Findings of the Association for Computational Linguistics: EMNLP 2024}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">paper</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2406.01171}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">EMNLP 2024</abbr> </div> <div id="hsueh2024editing" class="col-sm-8"> <div class="title">Editing the Mind of Giants: An In-Depth Exploration of Pitfalls of Knowledge Editing in Large Language Models</div> <div class="author"> Cheng-Hsun Hsueh,¬†Paul Kuo-Ming Huang,¬†Tzu-Han Lin, and <span class="more-authors" title="click to view 4 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '4 more authors' ? 'Che-Wei Liao, Hung-Chieh Fang, Chao-Wei Huang, Yun-Nung Chen' : '4 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">4 more authors</span> </div> <div class="periodical"> <em>In Findings of the Association for Computational Linguistics: EMNLP 2024</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/abs/2406.01436" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://github.com/MiuLab/EditLLM-Survey" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">hsueh2024editing</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Editing the Mind of Giants: An In-Depth Exploration of Pitfalls of Knowledge Editing in Large Language Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Hsueh, Cheng-Hsun and Huang, Paul Kuo-Ming and Lin, Tzu-Han and Liao, Che-Wei and Fang, Hung-Chieh and Huang, Chao-Wei and Chen, Yun-Nung}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Findings of the Association for Computational Linguistics: EMNLP 2024}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">paper</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2406.01436}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Arxiv</abbr> </div> <div id="huang2024instupr" class="col-sm-8"> <div class="title">InstUPR: Instruction-based Unsupervised Passage Reranking with Large Language Models</div> <div class="author"> <em>Chao-Wei Huang</em>,¬†and¬†<a href="https://www.csie.ntu.edu.tw/~yvchen/" rel="external nofollow noopener" target="_blank">Yun-Nung Chen</a> </div> <div class="periodical"> <em>arXiv preprint arXiv:2403.16435</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/abs/2403.16435" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://github.com/MiuLab/InstUPR" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">huang2024instupr</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{InstUPR: Instruction-based Unsupervised Passage Reranking with Large Language Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Huang, Chao-Wei and Chen, Yun-Nung}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2403.16435}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">paper</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2403.16435}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">SIGDIAL 2023</abbr> </div> <div id="huang2023converser" class="col-sm-8"> <div class="title">CONVERSER: Few-shot Conversational Dense Retrieval with Synthetic Data Generation</div> <div class="author"> <em>Chao-Wei Huang</em>,¬†Chen-Yu Hsu,¬†Tsu-Yuan Hsu, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Chen-An Li, Yun-Nung Chen' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the 24th Annual Meeting of the Special Interest Group on Discourse and Dialogue</em>, Sep 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://aclanthology.org/2023.sigdial-1.34/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://github.com/MiuLab/CONVERSER" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">huang2023converser</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{CONVERSER}: Few-shot Conversational Dense Retrieval with Synthetic Data Generation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Huang, Chao-Wei and Hsu, Chen-Yu and Hsu, Tsu-Yuan and Li, Chen-An and Chen, Yun-Nung}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 24th Annual Meeting of the Special Interest Group on Discourse and Dialogue}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Prague, Czechia}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/2023.sigdial-1.34}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{381--387}</span><span class="p">,</span>
  <span class="na">paper</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/2023.sigdial-1.34/}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ClinicalNLP 2022</abbr> </div> <div id="huang-etal-2022-plm" class="col-sm-8"> <div class="title">PLM-ICD: Automatic ICD Coding with Pretrained Language Models</div> <div class="author"> <em>Chao-Wei Huang</em>,¬†Shang-Chi Tsai,¬†and¬†<a href="https://www.csie.ntu.edu.tw/~yvchen/" rel="external nofollow noopener" target="_blank">Yun-Nung Chen</a> </div> <div class="periodical"> <em>In Proceedings of the 4th Clinical Natural Language Processing Workshop</em>, Jul 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="https://aclanthology.org/2022.clinicalnlp-1.2/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://github.com/MiuLab/PLM-ICD" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">huang-etal-2022-plm</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{PLM}-{ICD}: Automatic {ICD} Coding with Pretrained Language Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Huang, Chao-Wei and Tsai, Shang-Chi and Chen, Yun-Nung}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 4th Clinical Natural Language Processing Workshop}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Seattle, WA}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/2022.clinicalnlp-1.2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{10--20}</span><span class="p">,</span>
  <span class="na">paper</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/2022.clinicalnlp-1.2/}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICASSP 2020</abbr> </div> <div id="huang2020learning" class="col-sm-8"> <div class="title">Learning asr-robust contextualized embeddings for spoken language understanding</div> <div class="author"> <em>Chao-Wei Huang</em>,¬†and¬†<a href="https://www.csie.ntu.edu.tw/~yvchen/" rel="external nofollow noopener" target="_blank">Yun-Nung Chen</a> </div> <div class="periodical"> <em>In ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, Jul 2020 </div> <div class="periodical"> </div> <div class="links"> <a href="https://www.csie.ntu.edu.tw/%C2%A0yvchen/doc/ICASSP20_SpokenVec.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://github.com/MiuLab/SpokenVec" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.csie.ntu.edu.tw/%C2%A0yvchen/doc/ICASSP20_SpokenVec_slide.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Slides</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">huang2020learning</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learning asr-robust contextualized embeddings for spoken language understanding}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Huang, Chao-Wei and Chen, Yun-Nung}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{8009--8013}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">paper</span> <span class="p">=</span> <span class="s">{https://www.csie.ntu.edu.tw/~yvchen/doc/ICASSP20_SpokenVec.pdf}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ACL 2020</abbr> </div> <div id="huang-chen-2020-learning" class="col-sm-8"> <div class="title">Learning Spoken Language Representations with Neural Lattice Language Modeling</div> <div class="author"> <em>Chao-Wei Huang</em>,¬†and¬†<a href="https://www.csie.ntu.edu.tw/~yvchen/" rel="external nofollow noopener" target="_blank">Yun-Nung Chen</a> </div> <div class="periodical"> <em>In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>, Jul 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.aclweb.org/anthology/2020.acl-main.347/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://github.com/MiuLab/Lattice-ELMo" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.csie.ntu.edu.tw/%C2%A0yvchen/doc/ACL20_LatticeLM_slide.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Slides</a> </div> <div class="abstract hidden"> <p>Pre-trained language models have achieved huge improvement on many NLP tasks. However, these methods are usually designed for written text, so they do not consider the properties of spoken language. Therefore, this paper aims at generalizing the idea of language model pre-training to lattices generated by recognition systems. We propose a framework that trains neural lattice language models to provide contextualized representations for spoken language understanding tasks. The proposed two-stage pre-training approach reduces the demands of speech data and has better efficiency. Experiments on intent detection and dialogue act recognition datasets demonstrate that our proposed method consistently outperforms strong baselines when evaluated on spoken inputs. The code is available at https://github.com/MiuLab/Lattice-ELMo.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">huang-chen-2020-learning</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learning Spoken Language Representations with Neural Lattice Language Modeling}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Huang, Chao-Wei and Chen, Yun-Nung}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Online}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.aclweb.org/anthology/2020.acl-main.347}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{3764--3769}</span><span class="p">,</span>
  <span class="na">paper</span> <span class="p">=</span> <span class="s">{https://www.aclweb.org/anthology/2020.acl-main.347/}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ASRU 2019</abbr> </div> <div id="huang2019adapting" class="col-sm-8"> <div class="title">Adapting pretrained transformer to lattices for spoken language understanding</div> <div class="author"> <em>Chao-Wei Huang</em>,¬†and¬†<a href="https://www.csie.ntu.edu.tw/~yvchen/" rel="external nofollow noopener" target="_blank">Yun-Nung Chen</a> </div> <div class="periodical"> <em>In 2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)</em>, Jul 2019 </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/abs/2011.00780" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://github.com/MiuLab/Lattice-SLU" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">huang2019adapting</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Adapting pretrained transformer to lattices for spoken language understanding}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Huang, Chao-Wei and Chen, Yun-Nung}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{845--852}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">paper</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2011.00780}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%63%68%61%6F%77%65%69%68%75%61%6E%67.%75%73@%67%6D%61%69%6C.%63%6F%6D" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=nmsPLncAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/chaoweihuang" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/chao-wei-huang-89933a163" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://twitter.com/cwhuang_wh" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> </div> <div class="contact-note">The best way to reach me is via email. </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> ¬© Copyright 2024 Chao-Wei Huang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: October 18, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-SEL0950V43"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-SEL0950V43");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> </body> </html>